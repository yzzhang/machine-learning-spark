{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment\n",
    "\n",
    "* conda create -n python36 python=3.6 anaconda\n",
    "* conda activate python36\n",
    "* pip install koalas\n",
    "* pip install mlflow\n",
    "* pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "VFA_n4HYbeL5",
    "outputId": "358ec79a-8cf8-426e-830f-ccbe9bebaa16"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuhuang/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import databricks.koalas as ks\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from   datetime import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom pyspark import SparkContext\\n\\ntry:\\n    sc = SparkContext('local', 'Pyspark demo')\\nexcept ValueError:\\n    print('SparkContext already exist!')\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Spark 2.x, there is only one context - the SparkSession\n",
    "'''\n",
    "from pyspark import SparkContext\n",
    "\n",
    "try:\n",
    "    sc = SparkContext('local', 'Pyspark demo')\n",
    "except ValueError:\n",
    "    print('SparkContext already exist!')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom pyspark.sql import SparkSession\\ntry:\\n    spark = SparkSession.builder.appName('Recommendation_system').getOrCreate()\\nexcept ValueError:\\n    print('SparkSession already exists!')\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from pyspark.sql import SparkSession\n",
    "try:\n",
    "    spark = SparkSession.builder.appName('Recommendation_system').getOrCreate()\n",
    "except ValueError:\n",
    "    print('SparkSession already exists!')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom pyspark.sql import Row\\nfrom pyspark.sql import SQLContext\\n\\ntry:\\n    sqlContext = SQLContext(sc)\\nexcept ValueError:\\n    print('SQLContext already exists!')\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "try:\n",
    "    sqlContext = SQLContext(sc)\n",
    "except ValueError:\n",
    "    print('SQLContext already exists!')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dQ_HqJz1lclZ"
   },
   "source": [
    "The following code is going to upload the dataset csv file (e.g., Interview_Attendance_Data.csv) from your local machine. The dataset can be downloaded from Kaggle site: https://www.kaggle.com/vishnusraghavan/the-interview-attendance-problem/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OqKw66XKdQbj"
   },
   "source": [
    "Main Goals:\n",
    "\n",
    "\n",
    "\n",
    "1. Create a model predicting if a candidate will attend an interview. This will be indicated by the \"Observed Attendance\" column in the data set. Create the model only using the records where this column is not null\n",
    "\n",
    "2. Provide a probability and a prediction for the candidates where the \"Observed Attendance\" column is null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformColumn(column_values, func, func_type):\n",
    "    '''\n",
    "    This function is to transform a given column (column_values) of a Koalas DataFrame or Series.\n",
    "    This function is needed because the current Koalas requires that the applied function has \n",
    "    an explictly specified return type. Because of this, we cannot use lambda function directly \n",
    "    since lambda function does not have an explicit return type.\n",
    "    '''\n",
    "    def transform_column(column_element) -> func_type:\n",
    "        return func(column_element)\n",
    "    \n",
    "    cvalues = column_values\n",
    "        \n",
    "    cvalues = cvalues.apply(transform_column)\n",
    "            \n",
    "    return cvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "glg34AKsbpTg"
   },
   "outputs": [],
   "source": [
    "# https://www.guru99.com/pyspark-tutorial.html\n",
    "class OneHotEncodeData(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        This class is to one-hot encode the categorical features.\n",
    "        '''\n",
    "        self.one_hot_feature_names = ['Client name', \n",
    "                        'Industry', \n",
    "                        'Location', \n",
    "                        'Position to be closed', \n",
    "                        'Nature of Skillset',\n",
    "                        'Interview Type', \n",
    "                        #'Name(Cand ID)', \n",
    "                        'Gender', \n",
    "                        'Candidate Current Location',\n",
    "                        'Candidate Job Location', \n",
    "                        'Interview Venue', \n",
    "                        'Candidate Native location',\n",
    "                        'Have you obtained the necessary permission to start at the required time',\n",
    "                        'Hope there will be no unscheduled meetings',\n",
    "                        'Can I Call you three hours before the interview and follow up on your attendance for the interview',\n",
    "                        'Can I have an alternative number/ desk number. I assure you that I will not trouble you too much',\n",
    "                        'Have you taken a printout of your updated resume. Have you read the JD and understood the same',\n",
    "                        'Are you clear with the venue details and the landmark.',\n",
    "                        'Has the call letter been shared', \n",
    "                        'Marital Status']\n",
    "        self.label_encoders   = None\n",
    "        self.one_hot_encoders = None\n",
    "        \n",
    "    def fit(self, X, y=None):       \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):  \n",
    "        X1 = X.copy()\n",
    "        X1 = ks.get_dummies(X1)\n",
    "        return X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2N0ZOB3d8mh"
   },
   "outputs": [],
   "source": [
    "class FeaturesUppercase(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_names, drop_feature_names):\n",
    "        '''\n",
    "        This class is to change feature values to uppercase.\n",
    "        '''\n",
    "        self.feature_names      = feature_names\n",
    "        self.drop_feature_names = drop_feature_names\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        '''\n",
    "        This method is to change feature values to uppercase.\n",
    "        '''\n",
    "        \n",
    "        func = lambda x: x.strip().upper()\n",
    "        \n",
    "        #def transform_column(column_element) -> str:\n",
    "        #    return func(column_element)\n",
    "        \n",
    "        X_uppercase = X.copy()\n",
    "        \n",
    "        for fname in self.feature_names:\n",
    "            values = X_uppercase[fname]\n",
    "            values = values.fillna('NaN')\n",
    "            # values = values.apply(transform_column)\n",
    "            values = transformColumn(values, func, str)\n",
    "            X_uppercase[fname] = values\n",
    "        \n",
    "        # drop less important features\n",
    "        X_uppercase = X_uppercase.drop(self.drop_feature_names, axis=1)\n",
    "            \n",
    "        return X_uppercase   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tdbU3ZTTeHXp"
   },
   "outputs": [],
   "source": [
    "class ParseInterviewDate(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        This class is to splits the date of interview into day (2 digits), month (2 digits), year (4 digits).\n",
    "        '''     \n",
    "    def __parseDate(self, string, delimit):\n",
    "        try:\n",
    "            if ('&' in string):\n",
    "                subs = tuple(string.split('&'))\n",
    "                string = subs[0]\n",
    "        except:\n",
    "            print ('TypeError: {}'.format(string))\n",
    "            return None\n",
    "        \n",
    "        string = string.strip()\n",
    "        \n",
    "        try:\n",
    "            d = datetime.strptime(string, '%d{0}%m{0}%Y'.format(delimit))\n",
    "        except:\n",
    "            try:\n",
    "                d = datetime.strptime(string, '%d{0}%m{0}%y'.format(delimit))\n",
    "            except:\n",
    "                try:\n",
    "                     d = datetime.strptime(string, '%d{0}%b{0}%Y'.format(delimit))\n",
    "                except:\n",
    "                    try:\n",
    "                         d = datetime.strptime(string, '%d{0}%b{0}%y'.format(delimit))\n",
    "                    except:\n",
    "                        try:\n",
    "                            d = datetime.strptime(string, '%b{0}%d{0}%Y'.format(delimit))\n",
    "                        except:\n",
    "                            try:\n",
    "                                d = datetime.strptime(string, '%b{0}%d{0}%y'.format(delimit))\n",
    "                            except:\n",
    "                                d = None\n",
    "        return d\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        '''\n",
    "        This method splits the date of interview into day (2 digits), month (2 digits), year (4 digits).\n",
    "        '''\n",
    "        \n",
    "        def transform_date(ditem):\n",
    "            if (isinstance(ditem, str) and len(ditem) > 0):\n",
    "                if ('.' in ditem):\n",
    "                    d = self.__parseDate(ditem, '.')\n",
    "                elif ('/' in ditem):\n",
    "                    d = self.__parseDate(ditem, '/')\n",
    "                elif ('-' in ditem):\n",
    "                    d = self.__parseDate(ditem, '-')\n",
    "                elif (' ' in ditem):\n",
    "                    d = self.__parseDate(ditem, ' ')\n",
    "                else:\n",
    "                    d = None\n",
    "                    \n",
    "                if (d is None):\n",
    "                    return 0, 0, 0\n",
    "                else:\n",
    "                    return d.day, d.month, d.year\n",
    "                \n",
    "        def get_day(column_element) -> int:\n",
    "            try:\n",
    "                day, month, year = transform_date(column_element)\n",
    "                return int(day)\n",
    "            except:\n",
    "                return 0\n",
    "        \n",
    "        def get_month(column_element) -> int:\n",
    "            try:\n",
    "                day, month, year = transform_date(column_element)\n",
    "                return int(month)\n",
    "            except:\n",
    "                return 0\n",
    "        \n",
    "        def get_year(column_element) -> int:\n",
    "            try:\n",
    "                day, month, year = transform_date(column_element)\n",
    "                return int(year)\n",
    "            except:\n",
    "                return 0\n",
    "        \n",
    "        \n",
    "        X1 = X.copy()\n",
    "        \n",
    "        X1['Year'] = X1['Date of Interview']\n",
    "        X1['Month'] = X1['Date of Interview']\n",
    "        X1['Day'] = X1['Date of Interview']\n",
    "        \n",
    "        func_map = {'Year' : get_year, 'Month' : get_month, 'Day' : get_day}\n",
    "        for cname in func_map:\n",
    "            cvalue = X1[cname]\n",
    "            cvalue = cvalue.apply(func_map[cname])\n",
    "            X1[cname] = cvalue\n",
    "         \n",
    "        return X1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKyE5zV4eSZo"
   },
   "outputs": [],
   "source": [
    "class BucketSkillset(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        This class is to re-bucket the skill sets and candidates location features \n",
    "        to combine small catogaries into one catogary 'Others'.\n",
    "        '''\n",
    "        self.skillset = ['JAVA/J2EE/Struts/Hibernate', 'Fresher', 'Accounting Operations', 'CDD KYC', 'Routine', 'Oracle', \n",
    "          'JAVA/SPRING/HIBERNATE/JSF', 'Java J2EE', 'SAS', 'Oracle Plsql', 'Java Developer', \n",
    "          'Lending and Liabilities', 'Banking Operations', 'Java', 'Core Java', 'Java J2ee', 'T-24 developer', \n",
    "          'Senior software engineer-Mednet', 'ALS Testing', 'SCCM', 'COTS Developer', 'Analytical R & D', \n",
    "          'Sr Automation Testing', 'Regulatory', 'Hadoop', 'testing', 'Java', 'ETL', 'Publishing']       \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        '''\n",
    "        This method is to re-bucket the skill sets features.\n",
    "        '''\n",
    "        func = lambda x: x if x in self.skillset else 'Others'\n",
    "               \n",
    "        X1 = X.copy()\n",
    "        \n",
    "        cname = 'Nature of Skillset'\n",
    "        cvalue = X1[cname]\n",
    "        cvalue = transformColumn(cvalue, func, str)\n",
    "        X1[cname] = cvalue\n",
    "            \n",
    "        return X1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BucketLocation(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        This class is to re-bucket the candidates location features \n",
    "        to combine small catogaries into one catogary 'Others'.\n",
    "        '''\n",
    "        \n",
    "        self.candidate_locations = ['Chennai', 'Hyderabad', 'Bangalore', 'Gurgaon', 'Cuttack', 'Cochin', \n",
    "                          'Pune', 'Coimbatore', 'Allahabad', 'Noida', 'Visakapatinam', 'Nagercoil',\n",
    "                          'Trivandrum', 'Kolkata', 'Trichy', 'Vellore']\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        '''\n",
    "        This method is to re-bucket the candidates native locations features.\n",
    "        '''\n",
    "            \n",
    "        X1 = X.copy()\n",
    "        \n",
    "        func = lambda x: x if x in self.candidate_locations else 'Others'\n",
    "        \n",
    "        cname = 'Candidate Native location'\n",
    "        cvalue = X1[cname]\n",
    "        cvalue = transformColumn(cvalue, func, str)\n",
    "        X1[cname] = cvalue\n",
    "            \n",
    "        return X1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DN6TnUV8eaSe"
   },
   "outputs": [],
   "source": [
    "class GridSearch(object):\n",
    "    def __init__(self, cv=10):\n",
    "        '''\n",
    "        This class finds the best model via Grid Search.\n",
    "        '''\n",
    "        self.grid_param = [\n",
    "            {'n_estimators': range(68,69), # range(60, 70) # best 68\n",
    "             'max_depth'   : range(8,9)}   # range(5, 10)}  # best 8\n",
    "        ]\n",
    "        self.cv = cv\n",
    "        self.scoring_function = make_scorer(f1_score, greater_is_better=True) \n",
    "        self.gridSearch = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        rfc = RandomForestClassifier()\n",
    "        self.gridSearch = GridSearchCV(rfc, self.grid_param, cv=self.cv, scoring=self.scoring_function)\n",
    "        self.gridSearch.fit(X, y)\n",
    "        return self.gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9I-2iIeehfI"
   },
   "outputs": [],
   "source": [
    "class PredictInterview(object):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        This class is to predict the probability of a candidate attending scheduled interviews.\n",
    "        '''\n",
    "        self.dataset_file_name = 'Interview_Attendance_Data.csv'\n",
    "        self.feature_names = ['Date of Interview', \n",
    "                       'Client name', \n",
    "                       'Industry', \n",
    "                       'Location', \n",
    "                       'Position to be closed', \n",
    "                       'Nature of Skillset',\n",
    "                       'Interview Type', \n",
    "                       #'Name(Cand ID)',\n",
    "                       'Gender', \n",
    "                       'Candidate Current Location',\n",
    "                       'Candidate Job Location', \n",
    "                       'Interview Venue', \n",
    "                       'Candidate Native location',\n",
    "                       'Have you obtained the necessary permission to start at the required time',\n",
    "                       'Hope there will be no unscheduled meetings',\n",
    "                       'Can I Call you three hours before the interview and follow up on your attendance for the interview',\n",
    "                       'Can I have an alternative number/ desk number. I assure you that I will not trouble you too much',\n",
    "                       'Have you taken a printout of your updated resume. Have you read the JD and understood the same',\n",
    "                       'Are you clear with the venue details and the landmark.',\n",
    "                       'Has the call letter been shared', 'Marital Status']\n",
    "        \n",
    "        self.drop_feature_names = [\n",
    "                        'Name(Cand ID)',\n",
    "                        'Date of Interview', \n",
    "                        '_c22',\n",
    "                        '_c23',\n",
    "                        '_c24',\n",
    "                        '_c25',\n",
    "                        '_c26']\n",
    "        \n",
    "        self.dataset = None\n",
    "        self.rfc     = None\n",
    "        self.gridSearch = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_test  = None\n",
    "        self.y_test  = None\n",
    "        self.y_pred  = None\n",
    "        self.X_clean = None\n",
    "        self.y_clean = None\n",
    "        self.X_train_encoded = None\n",
    "        self.X_test_encoded  = None\n",
    "        self.y_train_encoded = None\n",
    "        self.accuracy_score  = None \n",
    "        self.f1_score        = None\n",
    "        self.oneHotEncoder   = None\n",
    "        self.X_test_name_ids = None\n",
    "        self.pipeline = None\n",
    "        \n",
    "        \n",
    "    def loadData(self, path=None):\n",
    "        '''\n",
    "        This method loads a dataset file as a Pandas DataFrame, assuming that the dataset file is in csv format.\n",
    "        It also shuffles the loaded dataset as part of data preprocessing.\n",
    "        '''\n",
    "        if (path != None):\n",
    "            path = os.path.join(path, self.dataset_file_name)\n",
    "        else:\n",
    "            path = self.dataset_file_name\n",
    "            \n",
    "        dataset = ks.read_csv(path)  \n",
    "        \n",
    "        # shuffle data \n",
    "        self.dataset = dataset.sample(frac=1.0) \n",
    "        \n",
    "        return self.dataset     \n",
    "    \n",
    "    def PreprocessData(self):\n",
    "        '''\n",
    "        This method preprocesses the loaded dataset before applying one-hot encoding.\n",
    "        '''\n",
    "            \n",
    "        y = self.dataset['Observed Attendance']      # extract labels y\n",
    "        X = self.dataset.drop('Observed Attendance') # extract features X\n",
    "        \n",
    "        self.oneHotEncoder = OneHotEncodeData()\n",
    "        \n",
    "        self.pipeline = Pipeline([\n",
    "            ('bucket_skillset', BucketSkillset()),\n",
    "            ('bucket_location', BucketLocation()),\n",
    "            ('parse_interview_date', ParseInterviewDate()),\n",
    "            ('features_to_uppercase', FeaturesUppercase(self.feature_names, self.drop_feature_names)),\n",
    "            ('one_hot_encoder', self.oneHotEncoder)\n",
    "        ])\n",
    "        \n",
    "        X_1hot = self.pipeline.fit_transform(X)\n",
    "        \n",
    "        # fill up missing labels and then change labels to uppercase\n",
    "        y = y.fillna('NaN')\n",
    "        \n",
    "        func = lambda x: x.strip().upper()\n",
    "        \n",
    "        y_uppercase = transformColumn(y, func, str) \n",
    "        \n",
    "        # separate labeled records from unlabeled records\n",
    "        self.X_train_encoded = X_1hot[y_uppercase != 'NAN']\n",
    "        self.X_test_encoded  = X_1hot[y_uppercase == 'NAN']\n",
    "        \n",
    "        # save Names/ID for reporting later one\n",
    "        self.X_test_name_ids = self.dataset['Name(Cand ID)'].loc[y_uppercase == 'NAN']\n",
    "        \n",
    "        y_train = y_uppercase.loc[y_uppercase != 'NAN']\n",
    "        \n",
    "        # encode labels as follows: 0 - NO, 1 - YES, NAN - NAN\n",
    "        func = lambda x: 1 if x == 'YES' else 0\n",
    "        \n",
    "        y = transformColumn(y_train, func, int)\n",
    "        \n",
    "        self.y_train_encoded = y\n",
    "        \n",
    "        self.X_clean = X_1hot\n",
    "        self.y_clean = y_uppercase\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def __splitData(self):\n",
    "        '''\n",
    "        This method triggers data preprocsssing and split dataset into training and testing datasets.\n",
    "        '''\n",
    "        X_train_encoded = self.X_train_encoded.to_numpy()\n",
    "        y_train_encoded = self.y_train_encoded.to_numpy()\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X_train_encoded, \n",
    "                                                                                y_train_encoded, \n",
    "                                                                                test_size = 0.25, random_state = 0)\n",
    "        return (self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "    \n",
    "    def trainModel(self):\n",
    "        '''\n",
    "        This method triggers splitting dataset and then find a best RandomForest model via grid search \n",
    "        using the training features and labels.\n",
    "        '''\n",
    "        X_train, X_test, y_train, y_test = self.__splitData()\n",
    "        self.gridSearch = GridSearch()\n",
    "        self.rfc = self.gridSearch.fit(X_train, y_train)\n",
    "        return self.rfc\n",
    "    \n",
    "    def predictClasses(self):\n",
    "        '''\n",
    "        This method predicts classes (YES or NO) using a trained model.\n",
    "        '''\n",
    "        if (self.rfc is None):\n",
    "            print(\"No trained model available, please train a model first!\")\n",
    "            return None\n",
    "        \n",
    "        self.y_pred = self.rfc.predict(self.X_test)\n",
    "        return self.y_pred\n",
    "    \n",
    "    def getModelMetrics(self):\n",
    "        '''\n",
    "        This method obtains the class prediction scores: (Accuracy Score, R2, F1).\n",
    "        '''\n",
    "        if (self.y_test is None or self.y_pred is None):\n",
    "            print('Failed to get model performance metrics because y_test is null or y_pred is null!')\n",
    "            return None\n",
    "        \n",
    "        self.accuracy_score = accuracy_score(self.y_test, self.y_pred)\n",
    "        self.f1_score = f1_score(self.y_test, self.y_pred)\n",
    "        \n",
    "        pred = self.predictAttendanceProbability(self.X_test)[:, 1]\n",
    "        actual = self.y_test.astype(float)\n",
    "        \n",
    "        self.rmse_score = np.sqrt(mean_squared_error(actual, pred))\n",
    "        self.mae_score = mean_absolute_error(actual, pred)\n",
    "        self.r2_score = r2_score(actual, pred)\n",
    "        \n",
    "        return (self.accuracy_score, self.f1_score, self.rmse_score, self.mae_score, self.r2_score)\n",
    "    \n",
    "    def predictNullAttendanceProbability(self):\n",
    "        '''\n",
    "        This method uses a trained model to predict the attendance probability for \n",
    "        the candidates where the \"Observed Attendance\" column is null.\n",
    "        '''\n",
    "        y_pred = self.rfc.predict_proba(self.X_test_encoded.to_numpy())\n",
    "        return y_pred\n",
    "    \n",
    "    def predictNullAttendanceClasses(self):\n",
    "        '''\n",
    "        This method predicts classes (YES or NO) using a trained model for unlabeled data records.\n",
    "        '''\n",
    "        y_pred = self.rfc.predict(self.X_test_encoded.to_numpy())\n",
    "        return y_pred\n",
    "    \n",
    "    def predictAttendanceProbability(self, X):\n",
    "        '''\n",
    "        Given one preprocessed (including one-hot encoding) data smaple X,\n",
    "        this method returns the probability of attendance probability.\n",
    "        '''\n",
    "        y_pred = self.rfc.predict_proba(X)\n",
    "        return y_pred\n",
    "    \n",
    "    def predictAttendanceClass(self, X):\n",
    "        '''\n",
    "        Given one preprocessed (including one-hot encoding) data smaple X,\n",
    "        this method returns the attendance Yes/No.\n",
    "        '''\n",
    "        y_pred = self.rfc.predict(X)\n",
    "        return y_pred\n",
    "    \n",
    "    def mlFlow(self):\n",
    "        '''\n",
    "        Training model in mlflow\n",
    "        * https://www.mlflow.org/docs/latest/tutorial.html\n",
    "        '''\n",
    "        np.random.seed(40)\n",
    "        with mlflow.start_run():\n",
    "            self.loadData()\n",
    "            self.PreprocessData()\n",
    "            self.trainModel()\n",
    "            self.predictClasses()\n",
    "            accuracy_score, f1_score, rmse_score, mae_score, r2_score = self.getModelMetrics()\n",
    "\n",
    "            print(\"Random Forest model:\")\n",
    "            print(\"  RMSE: {}\".format(rmse_score))\n",
    "            print(\"  MAE: {}\".format(mae_score))\n",
    "            print(\"  R2: {}\".format(r2_score))\n",
    "            print(\"Accuracy Score: {}\".format(accuracy_score))\n",
    "            print(\"  f1: {}\".format(f1_score))\n",
    "\n",
    "            mlflow.log_metric(\"rmse\", rmse_score)\n",
    "            mlflow.log_metric(\"r2\", r2_score)\n",
    "            mlflow.log_metric(\"mae\", mae_score)\n",
    "            mlflow.log_metric(\"accuracy\", accuracy_score)\n",
    "            mlflow.log_metric(\"f1\", f1_score)\n",
    "\n",
    "            mlflow.sklearn.log_model(self.rfc, \"random_forest_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YGJCZPyCeuiZ"
   },
   "source": [
    "Task 1 \n",
    "\n",
    "(a) Create a model predicting if a candidate will attend an interview. This will be indicated by the \"Observed Attendance\" column in the data set. Create the model only using the records where this column is not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8cn6g-Xgeoz5",
    "outputId": "b34e1965-2b48-4983-e181-41b0510c2892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model:\n",
      "  RMSE: 0.4222949212871352\n",
      "  MAE: 0.3818960214247194\n",
      "  R2: 0.1360433037540183\n",
      "Accuracy Score: 0.7298245614035088\n",
      "  f1: 0.8237986270022882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\npredictInterview.loadData()\\npredictInterview.PreprocessData()\\npredictInterview.trainModel()\\npredictInterview.predictClasses()\\naccuracy_score, f1_score = predictInterview.getModelMetrics()\\n\\nprint('accuracy score = {0}, F1 score = {1}'.format(accuracy_score, f1_score))\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictInterview = PredictInterview()\n",
    "predictInterview.mlFlow()\n",
    "\n",
    "'''\n",
    "predictInterview.loadData()\n",
    "predictInterview.PreprocessData()\n",
    "predictInterview.trainModel()\n",
    "predictInterview.predictClasses()\n",
    "accuracy_score, f1_score = predictInterview.getModelMetrics()\n",
    "\n",
    "print('accuracy score = {0}, F1 score = {1}'.format(accuracy_score, f1_score))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZxLwNNKfA8J"
   },
   "source": [
    "Task 1 \n",
    "\n",
    "(b) Provide a probability and a prediction for the candidates where the \"Observed Attendance\" column is null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3xVjeQ9jfKTO",
    "outputId": "138e594d-4c09-4525-e4b0-02f17a567f80"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names/ID</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Yes/No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Candidate 10</td>\n",
       "      <td>0.808386</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Candidate 20</td>\n",
       "      <td>0.868603</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Candidate 30</td>\n",
       "      <td>0.651773</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Candidate 40</td>\n",
       "      <td>0.68215</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Candidate 50</td>\n",
       "      <td>0.656323</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Candidate 1189</td>\n",
       "      <td>0.724846</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Candidate 1207</td>\n",
       "      <td>0.719133</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Candidate 1222</td>\n",
       "      <td>0.832814</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Candidate 1233</td>\n",
       "      <td>0.541941</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>None</td>\n",
       "      <td>0.283184</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Names/ID Probability Yes/No\n",
       "0     Candidate 10    0.808386    yes\n",
       "1     Candidate 20    0.868603    yes\n",
       "2     Candidate 30    0.651773    yes\n",
       "3     Candidate 40     0.68215    yes\n",
       "4     Candidate 50    0.656323    yes\n",
       "..             ...         ...    ...\n",
       "89  Candidate 1189    0.724846    yes\n",
       "90  Candidate 1207    0.719133    yes\n",
       "91  Candidate 1222    0.832814    yes\n",
       "92  Candidate 1233    0.541941    yes\n",
       "93            None    0.283184     no\n",
       "\n",
       "[94 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs   = predictInterview.predictNullAttendanceProbability()\n",
    "pred_classes = predictInterview.predictNullAttendanceClasses()\n",
    "\n",
    "x = predictInterview.X_test_name_ids.to_numpy() \n",
    "z = zip(x, pred_probs, pred_classes)\n",
    "answers = ('no', 'yes')\n",
    "\n",
    "result = [[x1, p1[1], answers[c]] for x1, p1, c in z]\n",
    "result_df = pd.DataFrame(np.array(result), columns=['Names/ID', 'Probability', 'Yes/No'])\n",
    "result_df.to_csv('interview_prediction.csv')\n",
    "result_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model in mlflow\n",
    "* https://www.mlflow.org/docs/latest/tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models in mlflow\n",
    "* https://www.mlflow.org/docs/latest/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start mlflow UI\n",
    "# ! mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging the training code\n",
    "* https://www.mlflow.org/docs/latest/tutorial.html\n",
    "\n",
    "conda env export > conda.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running project\n",
    "* https://www.mlflow.org/docs/latest/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mlflow run git@github.com:yzzhang/machine-learning-spark/tree/master/interview_attendance_problem.git"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "interview_attendance.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
